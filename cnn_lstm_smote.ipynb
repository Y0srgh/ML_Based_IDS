{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sampled_sdn_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Label']).values  # Features\n",
    "y = data['Label'].values  # Target (encoded 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for CNN-LSTM\n",
    "X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], X_train_resampled.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghozz\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build CNN-LSTM model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_resampled.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(100, return_sequences=False),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4610/4610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0093 - val_accuracy: 0.9988 - val_loss: 0.0065\n",
      "Epoch 2/10\n",
      "\u001b[1m4610/4610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0049 - val_accuracy: 0.9993 - val_loss: 0.0038\n",
      "Epoch 3/10\n",
      "\u001b[1m4610/4610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.9991 - val_loss: 0.0055\n",
      "Epoch 4/10\n",
      "\u001b[1m4610/4610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.9993 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "\u001b[1m4610/4610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0029 - val_accuracy: 0.9993 - val_loss: 0.0031\n",
      "Epoch 6/10\n",
      "\u001b[1m4610/4610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0049 - val_accuracy: 0.9992 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "\u001b[1m4610/4610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0042 - val_accuracy: 0.9992 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "\u001b[1m4610/4610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0059 - val_accuracy: 0.9991 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "\u001b[1m4610/4610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.9992 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "\u001b[1m4610/4610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.9978 - val_loss: 0.0142\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "start_time = time.time()\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "inference_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[16908    44]\n",
      " [   12 23036]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16952\n",
      "           1       1.00      1.00      1.00     23048\n",
      "\n",
      "    accuracy                           1.00     40000\n",
      "   macro avg       1.00      1.00      1.00     40000\n",
      "weighted avg       1.00      1.00      1.00     40000\n",
      "\n",
      "Accuracy: 0.9986\n",
      "Sensitivity: 0.9994793474488025\n",
      "Inference Time (seconds): 4.928214073181152\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Inference Time (seconds):\", inference_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "with open('cnn_lstm__smote_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download the union_dataset.csv file, please find the link in the readme file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the saved model on another dataset\n",
    "new_data = pd.read_csv('union_dataset.csv')  # Replace with actual test file path\n",
    "X_new = new_data.drop(columns=['Label']).values.reshape(-1, X_train_resampled.shape[1], 1)\n",
    "y_new = new_data['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cnn_lstm__smote_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31214/31214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Test the loaded model\n",
    "start_time = time.time()\n",
    "y_new_pred = (loaded_model.predict(X_new) > 0.5).astype(int)\n",
    "new_inference_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute new metrics\n",
    "new_conf_matrix = confusion_matrix(y_new, y_new_pred)\n",
    "new_report = classification_report(y_new, y_new_pred)\n",
    "new_accuracy = accuracy_score(y_new, y_new_pred)\n",
    "new_sensitivity = new_conf_matrix[1, 1] / (new_conf_matrix[1, 1] + new_conf_matrix[1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Dataset Results:\n",
      "Confusion Matrix:\n",
      " [[421530   1097]\n",
      " [   253 575938]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    422627\n",
      "           1       1.00      1.00      1.00    576191\n",
      "\n",
      "    accuracy                           1.00    998818\n",
      "   macro avg       1.00      1.00      1.00    998818\n",
      "weighted avg       1.00      1.00      1.00    998818\n",
      "\n",
      "Accuracy: 0.9986484024116505\n",
      "Sensitivity: 0.9995609094900822\n",
      "Inference Time (seconds): 118.52576184272766\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNew Dataset Results:\")\n",
    "print(\"Confusion Matrix:\\n\", new_conf_matrix)\n",
    "print(\"Classification Report:\\n\", new_report)\n",
    "print(\"Accuracy:\", new_accuracy)\n",
    "print(\"Sensitivity:\", new_sensitivity)\n",
    "print(\"Inference Time (seconds):\", new_inference_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
